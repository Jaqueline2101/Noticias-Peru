# Portal de Noticias Per√∫

Portal de noticias del Per√∫ con scraping autom√°tico de RPP y frontend en Angular.

## üöÄ Estructura del Proyecto

```
portal-noticias-peru/
‚îú‚îÄ‚îÄ scraper/          # Scraper de noticias (Python)
‚îú‚îÄ‚îÄ frontend/         # Frontend Angular
‚îî‚îÄ‚îÄ backend/          # Backend (futuro)
```

## üìã Requisitos Previos

- Python 3.11+
- Node.js 18+
- Angular CLI 17+
- Cuenta de Supabase

## üîß Configuraci√≥n

### 1. Supabase ya est√° configurado ‚úÖ

- **URL**: `https://unitbhhizdvtvsmplhon.supabase.co`
- **API Key**: Configurada en el c√≥digo

### 2. Crear tabla en Supabase

Crea una tabla `noticias` con la siguiente estructura:

```sql
CREATE TABLE noticias (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  titulo TEXT NOT NULL,
  volanta TEXT,
  bajada TEXT,
  contenido TEXT NOT NULL,
  autor TEXT NOT NULL,
  url TEXT NOT NULL UNIQUE,
  url_original TEXT,
  imagen_url TEXT NOT NULL,
  fecha_publicacion TIMESTAMP NOT NULL,
  categoria TEXT NOT NULL,
  medio_comunicacion TEXT NOT NULL,
  medio TEXT,
  idioma TEXT DEFAULT 'es',
  estado TEXT DEFAULT 'activa',
  fecha_scraping TIMESTAMP DEFAULT NOW(),
  pais TEXT DEFAULT 'Per√∫',
  tipo_contenido TEXT DEFAULT 'noticia',
  created_at TIMESTAMP DEFAULT NOW()
);
```

### 3. Configurar Scraper

1. Navega a la carpeta `scraper`:
```bash
cd scraper
```

2. Crea un entorno virtual:
```bash
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
# o
source venv/bin/activate  # Linux/Mac
```

3. Instala dependencias:
```bash
pip install -r requirements.txt
```

4. Las credenciales ya est√°n configuradas en el c√≥digo, no necesitas .env

5. Prueba la conexi√≥n:
```bash
python test_supabase_client.py
```

6. Ejecuta el scraper de 2025 (12 noticieros):
```bash
python scraper_noticieros_2025.py
```

Este scraper obtiene noticias de:
- RPP, El Comercio, La Rep√∫blica, Gesti√≥n, Per√∫21, Correo, Expreso, Ojo, Exitosa, Andina, El Peruano, y m√°s

### 4. Configurar Frontend Angular

1. Navega a la carpeta `frontend`:
```bash
cd frontend
```

2. Instala dependencias:
```bash
npm install
```

3. Las credenciales ya est√°n configuradas en `src/environments/environment.ts`

4. Ejecuta el servidor de desarrollo:
```bash
npm start
```

5. Abre tu navegador en `http://localhost:4200`

## üìù Notas Importantes

### Seguridad

- **NUNCA** subas el archivo `.env` al repositorio
- Usa la **Anon Key** en el frontend (p√∫blica pero con RLS)
- Usa la **Service Role Key** solo en el backend/scraper (privada)

### Row Level Security (RLS)

En Supabase, configura las pol√≠ticas RLS para la tabla `noticias`:

```sql
-- Permitir lectura p√∫blica
CREATE POLICY "Permitir lectura p√∫blica" ON noticias
FOR SELECT USING (true);

-- Permitir inserci√≥n solo desde el scraper (con service role key)
-- Esto se maneja autom√°ticamente con la service role key
```

## üõ†Ô∏è Scripts Disponibles

### Scraper
- `test_supabase_client.py` - Prueba la conexi√≥n con Supabase
- `scraper_supabase_v2.py` - Scraper principal (usa cliente oficial)
- `scraper_supabase.py` - Scraper alternativo (usa psycopg2)

### Frontend
- `npm start` - Servidor de desarrollo
- `npm run build` - Compilar para producci√≥n
- `npm test` - Ejecutar tests

## üìö Tecnolog√≠as Utilizadas

- **Backend/Scraper**: Python, BeautifulSoup, Supabase Client
- **Frontend**: Angular 17, TypeScript, Supabase JS
- **Base de Datos**: PostgreSQL (Supabase)

## üêõ Soluci√≥n de Problemas

### Error de conexi√≥n a Supabase

1. Verifica que las credenciales en `.env` sean correctas
2. Aseg√∫rate de que tu proyecto de Supabase est√© activo
3. Verifica las pol√≠ticas RLS en Supabase
4. Prueba la conexi√≥n con `test_supabase_client.py`

### Error en el frontend

1. Verifica que `supabaseKey` est√© configurado en `environment.ts`
2. Revisa la consola del navegador para errores
3. Verifica que la tabla `noticias` exista y tenga datos

## üìÑ Licencia

Ver archivo LICENSE


